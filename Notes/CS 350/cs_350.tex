\documentclass[12pt]{article}
\usepackage[margin = 1.5in]{geometry}
\setlength{\parindent}{0in}
\usepackage{amsfonts, amssymb, amsthm, mathtools, tikz, qtree, float}
\usepackage{algpseudocode, algorithm, algorithmicx}
\usepackage{ae, aecompl, color}
\usepackage{wrapfig}
\usepackage{multicol, multicol, array}
\usepackage{imakeidx}
\makeindex[columns=2, title=Indices, intoc]

\usepackage[pdftex, pdfauthor={Charles Shen}, pdftitle={CS 350: Operating Systems}, pdfsubject={Lecture notes from CS 350: at the University of Waterloo}, pdfkeywords={course notes, notes, Waterloo, University of Waterloo}, pdfproducer={LaTeX}, pdfcreator={pdflatex}]{hyperref}
\usepackage{cleveref}

\DeclarePairedDelimiter{\set}{\lbrace}{\rbrace}
\definecolor{darkish-blue}{RGB}{25,103,185}

\hypersetup{
  colorlinks,
  citecolor=darkish-blue,
  filecolor=darkish-blue,
  linkcolor=darkish-blue,
  urlcolor=darkish-blue
}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[subsection]

\theoremstyle{definition}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{ex}[theorem]{Example}
\newtheorem*{ex*}{Example}
\newtheorem{defn}{Definition}

\crefname{ex}{Example}{Example}

\setlength{\marginparwidth}{1.5in}
\newcommand{\lecture}[1]{
  \marginpar{{
    \footnotesize $\leftarrow$ \underline{#1}}
  }
}

\newcommand{\defnterm}[1]{\textbf{\textcolor{teal}{#1}}\index{#1}}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\allowdisplaybreaks

\makeatletter
\def\blfootnote{\gdef\@thefnmark{}\@footnotetext}
\makeatother

%%%%%%%%%%%%%%%%%%%%%
%% D O C U M E N T %%
%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\let\ref\Cref
\pagenumbering{roman}

\title{\bf{CS 350: Operating Systems}}
\date{Fall 2016, University of Waterloo \\ \center Notes written from Gregor Richards's lectures.}
\author{Charles Shen}

\blfootnote{Feel free to email feedback to me at
\href{mailto:ccshen902@gmail.com}{ccshen902@gmail.com}.}

\maketitle
\thispagestyle{empty}
\newpage
\tableofcontents
\newpage
\pagenumbering{arabic}

%%%%%%%%%%%%%%%%%%
%% INTRODUCTION %%
%%%%%%%%%%%%%%%%%%
\section{Introduction}
There are three views of an operating system:
\begin{enumerate}
  \item[1.] \textbf{Application View} (\ref{app_view_OS}): what service does it provide?
  \item[2.] \textbf{System View} (\ref{sys_view_OS}): what problems does it solve?
  \item[3.] \textbf{Implementation View} (\ref{impl_view_OS}): how is it built?
\end{enumerate}
\emph{An operating system is part cop, part facilitator}. \\

\textbf{kernel}: The operating system kernel is the part of the operating system that responds to system calls, interrupts and exception. \\

\textbf{operating system} (OS): The operating system as a whole includes the kernel, and may include other related programs that provide services for application such as utility programs, command interpreters, and programming libraries.

\subsection{Application View of an Operating System}\label{app_view_OS}
The OS provides an execution environment for running programs.
\begin{itemize}
  \item The execution environment provides a program with the processor time and memory space that it needs to run.
  \item The execution environment provides interfaces through which a program can use networks, storage, I/O devices, and other system hardware components. \\
  Interfaces provide a simplified, abstract view of hardware to application programs.
  \item The execution environment isolates running programs from one another and prevents undesirable interactions among them.
\end{itemize}

\subsection{System View of an Operating System}\label{sys_view_OS}
The OS manages the hardware resources of a computer system.
\begin{itemize}
  \item Resources include processors, memory, disks and other storage devices, network interfaces, I/O devices such as keyboards, mice and monitors, and so on.
  \item The operating system allocates resources among running programs. \\
  It controls the sharing of resources among programs.
  \item The OS itself also uses resources, which it must share with application programs.
\end{itemize}

\subsection{Implementation View of an Operating System}\label{impl_view_OS}
The OS is a concurrent, real-time program.
\begin{itemize}
  \item Concurrency arises naturally in an OS when it supports concurrent applications, and because it must interact directly with the hardware.
  \item Hardware interactions also impose timing constraints.
\end{itemize}

\subsection{Operating System Abstractions}
The execution environment provided by the OS includes a variety of abstract entities that can be manipulated by a running program. \\
Examples:
\begin{itemize}
  \item \textbf{files and file systems}: abstract view of secondary storage
  \item \textbf{address spaces}: abstract view of primary memory
  \item \textbf{processes, threads}: abstract view of program execution
  \item \textbf{sockets, pipes}: abstract view of network or other message channels
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% THREADS AND CONCURRENCY %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Threads and Concurrency}
Threads provide a way for programmers to express \emph{concurrency} in a program. \\
A normal \emph{sequential program} consists of a single thread of execution. \\
In threaded concurrent programs, there are multiple threads of executions that are all occurring at the same time.

\subsection{OS/161's Thread Interface}
Create a new thread:
\begin{verbatim}
  int thread_fork(
    const char *name,             // name of new thread
    struct proc *proc,            // thread's process
    void (*func)                  // new thread's function
      (void *, unsigned long),
    void *datat1,                 // function's first param
    unsigned long data2           // function's second param
  );
\end{verbatim}

Terminating the calling thread:
\begin{verbatim}
  void thread_exit(void);
\end{verbatim}

Voluntarily yield execution:
\begin{verbatim}
  void thread_yield(void);
\end{verbatim}

See \texttt{kern/include/thread.h}

\subsection{Why Threads?}
\textbf{Reason 1}: parallelism exposed by threads enables parallel execution if the underlying hardware supports it. \\
Programs can run faster! \\

\textbf{Reason 2}: parallelism exposed by threads enable better processor utilization. \\
If one thread has to \emph{block}, another may be able to run.

\textbf{Concurrent Program Execution (Two Threads)} \\
Conceptually, each thread executes sequentially using its private register contents and stack.

\subsection{Some Reviews}
\textbf{The Fetch/Execute Cycle}
\begin{enumerate}
  \item[1.] fetch instruction PC points to
  \item[2.] decode and execute instruction
  \item[3.] advance PC
\end{enumerate}

\begin{table}[ht]
  \caption{MIPS Registers}
  \centering

  \begin{tabular}{|c|c|l||c|c|l|}
  \hline
  num & name & use & num & name & use \\ \hline
  0 & z0 & always zero & 24-25 & t8-t9 & temps (caller-save) \\ \hline
  1 & at & assembler reserved & 26-27 & k0-k1 & kernel temps \\ \hline
  2 & v0 & return val/syscall \# & 28 & gp & global pointer \\ \hline
  3 & v1 & return value & 29 & sp & stack pointer \\ \hline
  4-7 & a0-a3 & subroutine args & 30 & s8/fp & frame ptr (callee-save) \\ \hline
  8-15 & t0-t7 & temps (caller-save) & 31 & ra & return addr (for jal) \\ \hline
  16-23 & s0-s7 & saved (calle-save) & & &  \\ \hline
  \end{tabular}
\end{table}

\subsection{Implementing Concurrent Threads}
\textbf{Option 1}: multiple processors, multiple cores, hardware multithreading per core
\begin{itemize}
  \item $P$ processors, $C$ cores per processor, $M$ multithreading degree per core $\Rightarrow$ $PCM$ threads can execute simultaneously
  \item separate register set for each running thread, to hold its execution context
\end{itemize}
\textbf{Option 2}: \emph{timesharing}
\begin{itemize}
  \item multiple threads take turns on the same hardware
  \item rapidly switch from thread to thread so that all make progress
\end{itemize}

In practice, both techniques can be combined!

\subsection{Timesharing and Context Switches}
When timesharing, the switch from one thread to another is called a \emph{context switch}. \\

What happens during a context switch:
\begin{enumerate}
  \item[1.] decide which thread will run next (scheduling)
  \item[2.] save register contents of current thread
  \item[3.] load register contents of next thread
\end{enumerate}

Thread context must be saved/restored carefully, since thread execution continuously changes the context! \\

\textbf{Context Switch on the MIPS}, see \texttt{kern/arch/mips/thread/switch.S}
\begin{verbatim}
  switchframe_switch:
    /* a0: address of switchframe pointer of old thread. */
    /* a1: address of switchframe pointer of new thread. */
    /* Allocate stack space for saving 10 registers. 10*4 = 40 */
    addi sp, sp, -40

    sw   ra, 36(sp)  /* Save the registers */
    sw   gp, 32(sp)
    sw   s8, 28(sp)
    sw   s6, 24(sp)
    sw   s5, 20(sp)
    sw   s4, 16(sp)
    sw   s3, 12(sp)
    sw   s2, 8(sp)
    sw   s1, 4(sp)
    sw   s0, 0(sp)

    /* Store the old stack pointer in the old thread */
    sw   sp, 0(a0)

    /* Get the new stack pointer from the new thread */
    lw   sp, 0(a1)
    nop             /* delay slot for load */

    lw   s0, 0(sp)  /* Now, restore the registers */
    lw   s1, 4(sp)
    lw   s2, 8(sp)
    lw   s3, 12(sp)
    lw   s4, 16(sp)
    lw   s5, 20(sp)
    lw   s6, 24(sp)
    lw   s8, 28(sp)
    lw   gp, 32(sp)
    lw   ra, 36(sp)
    nop             /* delay slot for load */

    /* and return. */
    j ra
    addi sp, sp, 40 /* in delay slot */
    .end switchframe_switch
\end{verbatim}

\subsection{What Causes a Context Switch?}
The running thread calls \texttt{thread\_yield}, running thread \emph{voluntarily} allows other threads to run. \\
So we have the following stack (in growth order) after voluntary context switch:
\begin{itemize}
  \item thread\_yield() stack frame
  \item thread\_switch() stack frame
  \item saved thread context (switchframe)
\end{itemize}

The running thread calls \texttt{thread\_exit}, running thread is terminated. \\

The running thread \emph{blocks}, via a call to \texttt{wchan\_sleep}. \\

The running thread is \emph{preempted}, running thread \emph{involuntarily} stops running. \\
So we have the following stack (in growth order) after preemption:
\begin{itemize}
  \item trap frame
  \item interrupt handling stack frame(s)
  \item thread\_yield() stack frame
  \item thread\_switch() stack frame
  \item saved thread context (switchframe)
\end{itemize}

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.6]{pictures/thread_states.png}
  \caption{Thread States}
  \label{fig:thread_states}
\end{figure}

\subsection{Preemption}
Without preemption, a running thread could potentially run forever, without yielding, blocking, or exiting. \\
\emph{Preemption} means forcing a running thread to stop running, so that another thread can have a chance. \\
To implement preemption, the thread library must have a means of ``getting control'' (causing thread library code to be executed) even though the running thread has not called a thread library function. \\
This is normally accomplished using \emph{interrupts}.

\subsection{Review on Interrupts}
An interrupt is an event that occurs during execution of a program. \\
Interrupts are caused by system devices (hardware), e.g., a timer, a disk controller, a network interface. \\
When an interrupt occurs, the hardware automatically transfer control to a fixed location in memory.
At that memory location, the thread library places a procedure called an \emph{interrupt handler}. \\
The interrupt handler normally:
\begin{enumerate}
  \item[1.] create a \emph{trap frame} to record thread context at the time of the interrupt
  \item[2.] determines which device caused the interrupt and performs device-specific processing
  \item[3.] restores the saved thread context from the trap frame and resumes executions of the thread
\end{enumerate}

\subsection{Preemptive Scheduling}
A preemptive scheduler imposes a limit, called the \emph{scheduling quantum} on how long a thread can run before being preempted. \\
The quantum is an \emph{upper bound} on the amount of time that a thread can run.
It may block or yield before its quantum has expired. \\
Periodic timer interrupts allow running time to be tracked. \\
If a thread has run too long, the timer interrupt handler preempts the thread by calling \texttt{thread\_yield}. \\
The preempted thread changes state from running to ready, and it is placed on the \emph{ready queue}. \\

OS/161 threads use \emph{preemptive round-robin scheduling}.

\subsection{Two-Thread Example}
Thread 1 is running, thread two had previously yielded voluntarily. \\
Thread 1: program stack frame(s). \\
Thread 2: program stack frame(s), thread\_yield, thread\_switch, switch frame. \\

A time interrupt occurs. Interrupt handler runs. \\
Thread 1: program stack frame(s), trap frame, interrupt handler. \\
Thread 2: program stack frame(s), thread\_yield, thread\_switch, switch frame. \\

Interrupt handler decides THread 1 quantum has expired. \\
Thread 1: program stack frame(s), trap frame, interrupt handler, thread\_yield. \\
Thread 2: program stack frame(s), thread\_yield, thread\_switch, switch frame. \\

Scheduler chooses Thread 2 to run. Context switch. \\
Thread 1: program stack frame(s), trap frame, interrupt handler, thread\_yield, thread\_switch, switch frame. \\
Thread 2: program stack frame(s), thread\_yield, thread\_switch, switch frame. \\

Thread 2 context is restored. \\
Thread 1: program stack frame(s), trap frame, interrupt handler, thread\_yield, thread\_switch, switch frame. \\
Thread 2: program stack frame(s), thread\_yield. \\

\texttt{thread\_yield} finishes, Thread 2 program resumes. \\
Thread 1: program stack frame(s), trap frame, interrupt handler, thread\_yield, thread\_switch, switch frame. \\
Thread 2: program stack frame(s). \\

Later, Thread 2 yields again. Scheduler chooses Thread 1. \\
Thread 1: program stack frame(s), trap frame, interrupt handler, thread\_yield, thread\_switch, switch frame. \\
Thread 2: program stack frame(s), thread\_yield, thread\_switch, switch frame. \\

Thread 1 context is restored, interrupt handler resumes. \\
Thread 1: program stack frame(s), trap frame, interrupt handler. \\
Thread 2: program stack frame(s), thread\_yield, thread\_switch, switch frame. \\

Interrupt handler restores state from trap frame and returns. \\
Thread 1: program stack frame(s). \\
Thread 2: program stack frame(s), thread\_yield, thread\_switch, switch frame.


%%%%%%%%%%%%%%%%%%%%%
%% SYNCHRONIZATION %%
%%%%%%%%%%%%%%%%%%%%%
\section{Synchronization}
\subsection{Thread Synchronization}
All threads in a concurrent program \emph{share access} to the program's global variables and the heap. \\
The part of a concurrent program in which a shared object is accessed is called a \emph{critical section}. \\

\texttt{volatile} keyword:
Without it, the compiler could optimize the code on the variable. \\
\texttt{volatile} forces the compiler to load and store the value on every use.
Otherwise, we may have a variable that is loaded before a loop and stored after the loop terminates which may not be what we want/expect.

\subsection{Mutual Exclusion}
To prevent race conditions, we can enforce \emph{mutual exclusion} on critical sections in the code. \\

A \emph{race condition} is an undesirable situation that occurs when a device or system attempts to perform two or more operations at the same time, but because of the nature of the device or system, the operations must be done in the proper sequence to be done correctly.

\subsubsection{Enforcing Mutual Exclusions With Locks}
Acquire/Release must ensure that only one thread at a time can hold the lock, even if both attempt to Acquire at the same time. \\
If a thread cannot Acquire the lock immediately, it must wait until the lock is available.

\subsection{Hardware-Specific Synchronization Instructions}
Used to implement synchronization primitives like locks. \\
Provide a way to \emph{test and set} a lock in a single \emph{atomic} (indivisible) operation. \\
\begin{ex*}
x86 \texttt{xchg} instruction:
\begin{verbatim}
  xchg  src, addr
\end{verbatim}
where \texttt{src} is typically a register, and \texttt{addr} is a memory address. \\
Value in register \texttt{src} is written to memory at address \texttt{addr}, and the old value at \texttt{addr} is placed into \texttt{src}.
\end{ex*}
Logical behaviour of \texttt{xchg} can be thought of as an \emph{atomic} function that behaves like this:
\begin{verbatim}
  Xchg(value,addr) {
    old = *addr;
    *addr = value;
    return(old);
  }
\end{verbatim}

\subsubsection{Lock Acquire and Release with Xchg}
\begin{verbatim}
  Acquire(bool *lock) {
    while (Xchg(true,lock) == true) ;
  }
  Release(book *lock) {
    *lock = false; /* give up the lock */
  }
\end{verbatim}
If \texttt{Xchg} returns \texttt{true}, the lock was already set, and we must continue to loop. \\
If \texttt{Xchg} returns \texttt{false}, then the lock was free, and we have now acquired it. \\

This construct is known as a \emph{spin lock}, since a thread busy-waits (loops) in Acquire until the lock is free!

\subsubsection{Other Synchronization Instructions}
SPARC \texttt{cas} instruction
\begin{verbatim}
  cas   addr, R1, R2
\end{verbatim}
if value at \texttt{addr} matches value in \texttt{R1} then swap contents of \texttt{addr} and \texttt{R2}. \\

Compare-And-Swap \\
\begin{verbatim}
  CompareAndSwap(addr, expectedval, newval)
    old = *addr;            // get old value at addr
    if (old == expectedval)
      *addr = newval;
    return old;
\end{verbatim}

MIPS load-linked and store-conditional \\
Load-linked returns the current value of a memory location, while a subsequent store-conditional to the same memory location will store a new value only if no updates have occurred to that location since the load-linked.

\subsection{Spinlocks in OS/1616}
\begin{verbatim}
  struct spinlock {
    volatile spinlock_data_t lk_lock;
    struct cpu *lk_holder;
  };
  void spinlock_init(struct spinlock *lk);
  void spinlock_acquire(struct spinlock *lk);
  void spinlock_release(struct spinlock *lk);
\end{verbatim}
\texttt{spinlock\_acquire} calls \texttt{spinlock\_data\_testandset} in a loop until the lock is acquired. \\
Using Load-Linked/Store-Conditional:
\begin{verbatim}
  /* return value 0 indicates lock was acquired */
  spinlock_data_testandset(volatile spinlock_data_t *sd) {
    spinlock_data_t x,y;
    y = 1;
    __asm volatile(
      ".set push;"      /* save assembler mode */
      ".set mips32;"    /* allow MIPS32 instructions */
      ".set volatile;"  /* avoid unwanted optimization */
      "ll %0, 0(%2);"   /* x = *sd */
      "sc %1, 0(%2);"   /* *sd = y; y = success? */
      ".set pop"        /* restore assembler mode */
      : "=r" (x), "+r" (y) : "r" (sd));
    if (y == 0) { return 1; }
  return x; }
\end{verbatim}

\subsection{OS/161 Locks}
In addition to spinlocks, OS/161 also has \emph{locks}. \\
Like spinlocks, locks are used to enforce mutual exclusion.
\begin{verbatim}
  struct lock *mylock = lock_create("LockName");

  lock_acquire(mylock);
    critical section
  lock_release(mylock);
\end{verbatim}

Spinlock \emph{spins}, locks \emph{blocks}:
\begin{itemize}
  \item a thread that calls \texttt{spinlock\_acquire} spins until the lock can be acquired
  \item a thread that called \texttt{lock\_acquire} \emph{blocks} until the lock can be acquired
\end{itemize}

\subsection{Thread Blocking}
Sometimes a thread will need to wait for something, e.g.:
\begin{itemize}
  \item wait for a lock to be released by another thread
  \item wait for data from a (relatively) slow device
  \item wait for input from a keyboard
  \item wait for busy device to become idle
\end{itemize}

When a thread blocks, it stops running:
\begin{enumerate}
  \item[i.] the scheduler chooses a new thread to run
  \item[ii.] a context switch from the blocking thread to the new thread occurs
  \item[iii.] the blocking thread is queued in a \emph{wait queue} (not on the ready list)
\end{enumerate}

Eventually, a blocked thread is signalled and awakened by another thread.

\subsection{Wait Channels in OS/161}
Wait channels are used to implement thread blocking in OS/161.
\begin{itemize}
  \item \texttt{void wchan\_sleep (struct wchan *wc);} \\
  blocks calling thread on wait channel \texttt{wc} \\
  causes a context switch, like \texttt{thread\_yield}
  \item \texttt{void wchan\_wakeall (struct wchan *wc);} \\
  unblocks all threads sleeping on waiting channel \texttt{wc}
  \item \texttt{void wchan\_wakeone (struct wchan *wc);} \\
  unblocks one thread sleeping on waiting channel \texttt{wc}
  \item \texttt{void wchan\_lock (struct wchan *wc);} \\
  prevent operations on wait channel \texttt{wc}
\end{itemize}
There can be many different wait channels, holding threads that are blocked for different reasons.

\subsection{Thread States, Revisited}
Refer to \ref{fig:thread_states}. \\
Ready threads are queued on the ready queue, blocked threads are queued on wait channels.

\subsection{Semaphores}
A semaphore is a synchronization primitive that can be used to enforce mutual exclusion requirements.
It can also be used to solve other kinds of synchronization problems. \\

A semaphore is an object that has an integer value, and that supports two operations (\emph{atomic} by definition):
\begin{itemize}
  \item[\textbf{P}:] if the semaphore value is greater than 0, decrement the value. \\
  Otherwise, wait until the value is greater than 0 and then decrement it.
  \item[\textbf{V}:] increment the value of the semaphore
\end{itemize}

\subsection{Condition Variables in OS/161}
Each cv is purposed to work together along with a lock: cvs are used \emph{from within the critical section protected by the lock}. \\
Supported operations:
\begin{itemize}
  \item[\textbf{wait}:] causes calling thread to block, and it releases the lock associated within the cv. \\
  Once the thread is unblocked, it reacquires the lock.
  \item[\textbf{signal}:] one of the threads blocked on the signalled cv is unblocked
  \item[\textbf{broadcast}:] all threads blocked on the cv are unblocked
\end{itemize}

\subsubsection{Using Condition Variables}
Cvs allow threads to wait for arbitrary conditions to become true inside of a critical section. \\
By convention, each cv corresponds to a particular condition of interest to an application. \\
When a condition is not true, a thread can \texttt{wait} on the corresponding cv until it becomes true. \\
When a thread detects that a condition is true, it uses \texttt{signal} or \texttt{broadcast} to notify any threads that may be waiting. \\

Note: signalling (or broadcasting to) a cv that has no waiting threads has \emph{no effect}.
Signals \emph{do not} accumulate.

\subsubsection{Waiting on Condition Variables}
The OS/161 condition variables follows the Mesa-style condition variables. \\
When a blocked thread is unblocked, it reacquires the lock before returning from the \texttt{wait} call. \\
A thread is in the critical section when it calls \texttt{wait}, and it will be in the critical section when \texttt{wait} returns.
In between the call and the return, while the caller is blocked, the caller is \emph{out} of the critical section, and other threads may enter! \\
The thread that calls \texttt{signal} (or \texttt{broadcast}) to wake up the waiting thread will itself be in the critical section when it signals.
The waiting threads need to wait until the signaller releases the lock before it unblocks and return from the \texttt{wait} call.

\subsubsection{Example}
\begin{verbatim}
  int volatile count = 0;
  struct lock *mutex;
  struct cv *notfull, *notempty;
  /* Initialization Note: the lock and cv’s must be created
   * using lock_create() and cv_create() before Produce()
   * and Consume() are called
   */
  Produce(itemType item) {            itemType Consume() {
    lock acquire(mutex);                lock_acquire(mutex);
    while (count == N) {                while (count == 0)
      cv_wait(notfull, mutex);            cv_wait(nonempty, mutex);
    }                                   remove item from buffer
    add item to buffer                  count = count - 1;
    count = count + 1;                  cv_signal(notfull, mutex);
    cv_signal(notempty, mutex);         lock_release(mutex);
    lock release(mutex);                return(item);
  }                                   }
\end{verbatim}

\subsection{Deadlocks}
Threads are \emph{deadlocked} when none of the threads can make progress (i.e. waiting on a lock indefinitely). \\
Waiting does not resolve the deadlock. \\
Those threads are permanently stuck.

\subsubsection{Two Techniques for Deadlock Prevention}
\textbf{No Hold and Wait}:
prevent a thread from requesting resources if it currently has resources allocated to it. \\
A thread may hold several resources, but to do so it must make a single request for all of them. \\

\textbf{Resource Ordering}:
Order the resource types, and require that each thread acquire resources in increasing resource type order. \\
That is, a thread may make no request for resources of type less than or equal to $i$ if it is holding resources of type $i$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% PROCESSES AND SYSTEM CALLS %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Processes and System Calls}
\subsection{What is a Process?}
A \emph{process} is an environment in which an application program runs. \\
A process includes virtualized \emph{resources} that its program can use:
\begin{itemize}
  \item one (or more) threads
  \item virtual memory, used for the program's code and data
  \item other resources
\end{itemize}
Processes are created and managed by the \emph{kernel}. \\
Each program's process \emph{isolates} it from other programs in other processes.

\subsection{System Calls}
System calls (syscalls) are the interface between processes and the kernel. \\
A process uses syscalls to request operating system services.
\begin{table}[ht]
  \caption{Syscall examples}
  \label{tab:ex_syscall}
  \centering
  \begin{tabular}{c|l}
  Services & OS/161 Examples \\ \hline
  create, destroy, manage processes & \texttt{fork, execv, waitpid, getpid} \\
  create, destroy, read, write files & \texttt{open, close, remove, read, write} \\
  manage file system and directories & \texttt{mkdir, rmdir, link, sync} \\
  interprocess communication & \texttt{pipe, read, write} \\
  manage virtual memory & \texttt{sbrk} \\
  query, manage system & \texttt{reboot, \_time}
  \end{tabular}
\end{table}

\subsection{Kernel Privilege}
Kernel code runs at a higher level of \emph{execution privilege} than application code. \\
Privilege levels are implemented by the CPU. \\

The kernel's higher privilege level allows it to do things that the CPU prevents less-privileged (application) programs from doing, like
\begin{itemize}
  \item application programs cannot modify the page tables that the kernel uses to implement process virtual memories
  \item application programs cannot halt the CPU
\end{itemize}

These restrictions allow the kernel to keep processes isolated from one another --- and from the kernel. \\

\textbf{Note}: application programs cannot directly call kernel functions or access kernel data structures.

\subsection{How System Calls Work}
There are only \emph{two} things that make kernel code run! \\

On the MIPS, the same mechanism handles exceptions and interrupts, and there is a single handler for both in the kernel.
The handler uses these codes to determine what triggered it to run.

\subsubsection{Interrupts}
Interrupts are generated by devices. \\
An interrupt means a device (hardware) needs attention. \\

Recall that an interrupt causes the hardware to transfer control to a fixed location in
memory, where an \emph{interrupt handler} is located. \\

Interrupt handlers are part of the kernel. \\
If an interrupt occurs while an application program is running, control will jump from the application to the kernel’s interrupt handler. \\

When an interrupt occurs, the processor switches to privileged execution mode when it transfers control to the interrupt handler.
This is how the kernel gets its execution privilege.

\subsubsection{Exceptions}
Exceptions are caused by instruction execution. \\
An exception means that a running program needs attention. \\

Exceptions are conditions that occur during the execution of a program instruction. \\
Examples: arithmetic overflows, illegal instructions, or page faults. \\

Exceptions are detected by the CPU during instruction execution. \\

The CPU handles exceptions like it handles interrupts:
\begin{itemize}
  \item control is transferred to a fixed location, where an \emph{exception handler} is located
  \item the processor is switched to privileged execution mode
\end{itemize}
The exception handler is part of the kernel \\

\textbf{MIPS Exception Types}:
\begin{verbatim}
  EX_IRQ    0     /* Interrupt */
  EX_MOD    1     /* TLB Modify (write to read-only page) */
  EX_TLBL   2     /* TLB miss on load */
  EX_TLBS   3     /* TLB miss on store */
  EX_ADEL   4     /* Address error on load */
  EX_ADES   5     /* Address error on store */
  EX_IBE    6     /* Bus error on instruction fetch */
  EX_DBE    7     /* Bus error on data load *or* store */
  EX_SYS    8     /* Syscall */
  EX_BP     9     /* Breakpoint */
  EX_RI     10    /* Reserved (illegal) instruction */
  EX_CPU    11    /* Coprocessor unusable */
  EX_OVF    12    /* Arithmetic overflow */
\end{verbatim}

\subsubsection{Performing a Syscall}
To perform a syscall, the application program needs to cause an exception to make the kernel execute! \\
The kernel's exception handler checks the exception code (set by the CPU when the exception is generated) to distinguish syscall exceptions from other types of exceptions. \\

On the MIPS, \texttt{EX\_SYS} is the syscall exception. \\
To cause this exception on the MIPS, the application executes a special purpose instruction: \texttt{syscall}.
Other processor instruction sets include similar instructions, e.g., \texttt{syscall} on x86.

\subsubsection{System Call Timeline}
\begin{figure}[!ht]
  \centering
  \includegraphics[scale=0.39]{pictures/syscall_stack.png}
  \caption{System call software stack}
  \label{fig:syscall_stack}
\end{figure}
\begin{enumerate}
  \item[1.] application calls library wrapper function for desired system call
  \item[2.] library function performs \texttt{syscall} instruction
  \item[3.] kernel exception handler runs
  \begin{itemize}
    \item creates a trap frame to save application program state
    \item determines that this is a syscall exception
    \item determines which syscall is being requested
    \item does the work for the requested system call
    \item restores the application program state from the trap frame
    \item returns from the exception
  \end{itemize}
  \item[4.] library wrapper function finishes and returns from its call
  \item[5.] application continues execution
\end{enumerate}

\subsubsection{Which Syscall?}
The kernel uses system call codes to determine which syscall the application is requesting,
\begin{itemize}
  \item the kernel defines a code for each syscall it understands
  \item the kernel expects the application to place a code in a specified location before executing the \texttt{syscall} instruction. \\
  For OS/161 on the MIPS, the code goes in register \texttt{v2}
  \item the kernel's exception handler checks this code to determine which system call has been requested
  \item the codes and and code location are part of the \emph{kernel ABI} (Application Binary Interface)
\end{itemize}

\subsubsection{Syscall Parameters}
The application places parameter values in kernel-specified locations before the \texttt{syscall}, and looks for return values in kernel-specified locations after the exception handler returns,
\begin{itemize}
  \item The locations are part of the kernel ABI
  \item Parameter and return value placement is handled by the application system call library functions
  \item On the MIPS
  \begin{itemize}
    \item parameters go in registers \texttt{a0, a1, a2, a3}
    \item result success/fail code is in \texttt{a3} on return
    \item return value or error code is in \texttt{v0} on return
  \end{itemize}
\end{itemize}

\subsection{User and Kernel Stacks}
Every OS/161 process thread has two stacks, although it only uses one at a time. \\

\textbf{User (Application) Stack}: used while application code is executing,
\begin{itemize}
  \item this stack is located in the application's virtual memory
  \item it holds activation records for application functions
  \item the kernel creates this stack when it sets up the virtual address memory for the process
\end{itemize}

\textbf{Kernel Stack}: used while the thread is executing kernel code, after an exception or interrupt,
\begin{itemize}
  \item this stack is a kernel structure
  \item in OS/161, the \texttt{t\_stack} field of the \texttt{thread} structure points to this stack
  \item this stack holds activation records for kernel functions
  \item this stack also holds \emph{trap frames} and \emph{switch frames} (because the kernel creates trap frames and switch frames)
\end{itemize}

\subsection{Exception Handling in OS/161}
First to run is careful assembly code that
\begin{itemize}
  \item saves the application stack pointer
  \item switches the stack pointer to point to the thread's kernel stack
  \item carefully saves application state and the address of the instruction that was interrupted in a trap frame on the thread's kernel stack
  \item calls \texttt{mips\_trap}, passing a pointer to the trap frame as a parameter
\end{itemize}

After \texttt{mips\_trap} is finished, the handler will
\begin{itemize}
  \item restore application state (including the application stack pointer) from the trap frame on the thread's kernel stack
  \item jump back to the application instruction that was interrupted, and switch back to unprivileged execution mode
\end{itemize}

\subsubsection{mips\_trap}
\texttt{mips\_trap} determines what type of exception this is by looking at the exception code. \\
There is a separate handler in the kernel for each type of exception:
\begin{itemize}
  \item interrupt? call \texttt{mainbus\_interrupt}
  \item address translation exception? call \texttt{vm\_fault}
  \item system call? call \texttt{syscall} (kernel function), passing it the trap frame pointer
\end{itemize}

\subsection{Multiprocessing}
Multiprocessing (or multitasking) means having multiple processes existing at the same time. \\

All processes share the available hardware resources, with the sharing coordinated by the OS:
\begin{itemize}
  \item Each process' virtual memory is implemented using some of the available physical memory. \\
  The OS decides how much memory each process gets.
  \item Each process' threads are scheduled onto the available CPUs (or CPU cores) by the OS.
  \item Processes share access to other resources (e.g., disks, network devices, I/O devices) by making syscalls. \\
  The OS controls this sharing.
\end{itemize}

The OS ensures that processes are isolated from one another. \\
Interprocess communication should be possible, but only at the explicit request of the processes involved.

\begin{table}[h]
  \caption{Syscalls for Process Management}
  \label{tab:syscall_pmanage}
  \centering

  \begin{tabular}{|c||c|c|}
  \hline
  & Linux & OS/161 \\ \hline
  Creation & \texttt{fork, execv} & \texttt{fork, execv} \\ \hline
  Destruction & \texttt{\_exit, kill} & \texttt{\_exit} \\ \hline
  Synchronization & \texttt{wait, waitpid, pause, ...} & \texttt{waitpid} \\ \hline
  Attribute Mgmt & \texttt{getpid, getuid, nice, getrusage, ...} & \texttt{getpid} \\ \hline
  \end{tabular}
\end{table}

\subsection{\texttt{fork}, \texttt{\_exit}, and \texttt{waitpid}}
\texttt{fork} creates a new process (the \emph{child}) that is a clone of the original (the \emph{parent}),
\begin{itemize}
  \item after \texttt{fork}, both parent and child are executing copies of the same program
  \item virtual memories of parent and child are identical at the time of the fork, but may diverge afterwards
  \item \texttt{fork} is called by the parent, but returns in \emph{both} the parent and the child! \\
  Parent and child see different return values from \texttt{fork}, parent gets child's pid and child gets 0.
\end{itemize}

\texttt{\_exit} terminates the process that calls it,
\begin{itemize}
  \item process can supply an exit status code when it exits
  \item kernel records the exit status code in case another process asks for it (via \texttt{waitpid})
\end{itemize}

\texttt{waitpid} lets a process wait for another to terminate, and retrieve its exit status code.

\subsection{The \texttt{execv} system call}
\texttt{execv} changes the program that a process is running. \\
The calling process's current virtual memory is destroyed. \\
The process gets a new virtual memory, initialized with the code and data of the new program to run. \\
After \texttt{execv}, the new program starts executing.

%%%%%%%%%%%%%%%%%%%%%%%%%%
%% ASSIGNMENT 2A REVIEW %%
%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Assignment 2A Review}
\subsection{\texttt{fork}}
\begin{enumerate}
  \item[i.] Create process structure for child process. \\
  Use \texttt{proc\_create\_runprogram} to create the process structure, sets up the VFS and console.
  \item[ii.] Create and copy address space (and data) from parent to child. \\
  Child process must be identical to the parent process. \\
  \texttt{as\_copy} creates a new address space, and copies the pages from the old address space to the new one. \\
  Address space is not associated with the new process yet.
  \item[iii.] Attach the newly created address space to the child process structure.
  \item[iv.] Assign PID to child process and create the parent/child relationship. \\
  PIDs should be unique (no two processes should have the same PID). \\
  PIDs should be reusable.
  \item[v.] Create thread for child process (need a safe way to pass the trapframe to the child thread). \\
  Use \texttt{thread\_fork} to create a new thread. \\
  Need to pass trapframe to the child thread.
  \item[vi.] Child thread needs to put the trapframe onto the stack and modify it so that it returns the current value (and executes the next instruction)
  \item[vii.] Call \texttt{mips\_usermode} in the child to go back to userspace
\end{enumerate}

\textbf{Note}: need to ensure that the new thread does not go to user mode until its address space and trap frame have been set up (requires synchronization)!
In addition, the parent process must not return to user mode until its address space and trap frame have been copied.

\subsection{\texttt{waitpid}}
Only the parent can call \texttt{waitpid} on its children. \\
If \texttt{waitpid} is called before the child process exits, then the parent must wait/block. \\
If \texttt{waitpid} is called after the child process has exited, then the parent should immediately get the exit status and exit code. \\
PID cleanup should not rely on \texttt{waitpid}.
Parent process is not guaranteed to call \texttt{waitpid} when it exits.

\subsection{\texttt{getpid}}
Returns the PID of the current process. \\
Need to perform process assignment even without/before any fork calls.
The first user process might call \texttt{getpid} before creating any children.
\texttt{getpid} needs to return a valid PID for this process.

\subsection{\texttt{\_exit}}
Causes the current process to exit. \\
Exit code is passed to the parent process

%%%%%%%%%%%%%%%%%%%%%%%%%%
%% ASSIGNMENT 2B REVIEW %%
%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Assignment 2B Review}

%%%%%%%%%%%%%%%%%%%%
%% VIRTUAL MEMORY %%
%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Virtual Memory}
\subsection{Physical Memory and Addresses}
\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.65]{pictures/phys_mem.png}
  \caption{An example physical memory, $P = 18$}
  \label{fig:phys_mem}
\end{figure}
If physical addresses have $P$ \emph{bits}, the maximum amount of addressable physical memory is $2^{P}$ \emph{bytes} (assuming a byte-addressable machine).
\begin{itemize}
  \item Sys/161 MIPS processor uses 32 bit physical addresses ($P = 32$) $\Rightarrow$ maximum physical memory size of $2^32$ bytes, or 4GB
  \item Larger values of $P$ are common on modern processors, e.g., $P = 48$, which allows 256TB of physical memory to be addressed
\end{itemize}

The actual amount of physical memory on a machine may be less than the maximum amount that can be addressed.

\subsection{Virtual Memory and Addresses}
\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.65]{pictures/v_mem.png}
  \caption{An example of virtual memory, $V = 16$}
  \label{fig:v_mem}
\end{figure}
The kernel provides a separate, private \emph{virtual} memory for each process. \\
The virtual memory of a process holds the code, data, and stack for the program that is running in that process. \\
If virtual addresses are $V$ bits, the \emph{maximum} size of a virtual memory is $2^{V}$ bytes.
\begin{itemize}
  \item For the MIPS, $V = 32$
\end{itemize}
Running applications see only virtual addresses, e.g.,
\begin{itemize}
  \item program counter and stack pointer hold \emph{virtual addresses} of the next instruction and the stack
  \item pointers to variables are \emph{virtual addresses}
  \item jumps/branches refer to \emph{virtual addresses}
\end{itemize}
Each process is isolated in its virtual memory, and cannot access other process' virtual memories.

\subsection{Address Translation}
Each virtual memory is mapped to a different part of physical memory. \\
Since virtual memory is not real, when an process tries to access (load or store) a virtual address, the virtual address is \emph{translated} (mapped) to its corresponding physical address, and the load or store is performed in physical memory. \\
Address translation is performed in hardware, using information provided by the kernel.

\subsection{Address Translation for Dynamic Relocation}
\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.6]{pictures/dyn_reloc.png}
  \caption{Example of dynamic relocation}
  \label{fig:dyn_reloc_ex}
\end{figure}
CPU includes a \emph{memory management unit} (MMU), with a \emph{relocation register} and a \emph{limit register}.
\begin{itemize}
  \item relocation register holds the physical offset ($R$) for the running process' virtual memory
  \item limit register holds the size $L$ of the running process' virtual memory
\end{itemize}
To translate a virtual address $v$ to a physical address $p$:
\begin{align*}
&\texttt{if } v \geq L \texttt{ then generate exception} \\
&\texttt{else} \\
&\qquad p \leftarrow v + R
\end{align*}
Translation is done in hardware by the MMU. \\
The kernel maintains a separate $R$ and $L$ for each process, and changes the values in the MMU registers when there is a context switch between processes. \\

\begin{ex*}
$v = \texttt{0x102c} \qquad p = \texttt{0x102c} + \texttt{0x24000} = \texttt{0x2502c}$ \\
$v = \texttt{0x8800} \qquad p = \texttt{exception}$ since $\texttt{0x8800} \geq \texttt{0x7000}$
\end{ex*}

\subsection{Properties of Dynamic Relocation}
Each virtual address space corresponds to a \emph{contiguous range of physical addresses}. \\
The kernel is responsible for deciding \emph{where} each virtual address space should map in physical memory.
\begin{itemize}
  \item the OS must track which part of physical memory are in use, and which parts are free
  \item since different address spaces may have different sizes, the OS must allocate/deallocate variable-sized chunks of physical memory
  \item hence creates potential for \emph{fragmentation} of physical memory
\end{itemize}

\subsection{Paging: Physical Memory}
Physical memory is divided into fixed-size chunks called \emph{frames} or \emph{physical pages}.
\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.7]{pictures/paging_phys_mem.png}
  \caption{The frame size if $2^{12}$ bytes (4KB)}
  \label{fig:p_phys_mem}
\end{figure}

\subsection{Paging: Virtual Memory}
Virtual memories are divided into fixed-size chunks called \emph{pages}. \\
Page size is equal to frame size.
\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.8]{pictures/paging_v_mem.png}
  \caption{Page size is 4KB here}
  \label{fig:p_v_mem}
\end{figure}

\subsection{Paging: Address Translation}
\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.7]{pictures/p_translation.png}
  \label{fig:p_trans}
\end{figure}
Each page maps to a different frame.
Any page can map to any frame.

\subsection{Paging: Address Translation}
The MMU includes a \emph{page table base register} which points to the page table for the current process. \\

How the MMU translate a virtual address:
\begin{enumerate}
  \item[1.] determines the \emph{page number} and \emph{offset} of the virtual address
  \begin{itemize}
    \item page number is the virtual address divided by the page size
    \item offset is the virtual address modulo the page size
  \end{itemize}
  \item[2.] looks up the page's entry (PTE) in the current process page table, using the page number
  \item[3.] if the PTE is not valid, raise an exception
  \item[4.] otherwise, combine page's frame number from the PTE with the offset to determine the physical address;
  physical address is $(\text{frame number} \cdot \text{frame size}) + \text{offset}$ \\
\end{enumerate}

\subsection{Other Information Found in PTEs}
PTEs may contain other fields, in addition to the frame number and valid bit. \\

Example 1: write protection bit
\begin{itemize}
  \item can be set by the kernel to indicate that a page is read-only
  \item if a write operation (e.g., MIPS \texttt{lw}) uses a virtual address on a read-only page, the MMU will raise an exception when it translate the virtual address
\end{itemize}

Example 2: bits to track page usage
\begin{itemize}
  \item reference (use) bit: has the process used this page recently?
  \item dirty bit: have contents of this page been changed?
  \item these bits are set by the MMU, and read by the kernel
\end{itemize}

\subsection{Page Tables: How Big?}
A page table has one PTE for each page in the virtual memory
\begin{itemize}
  \item $\text{page table size} = \text{number of pages} \cdot \text{size of PTE}$
  \item $\text{number of pages} = \frac{\text{virtual memory size}}{\text{page size}}$
\end{itemize}
The page table a 64KB virtual memory, with 4KB pages, is 64 bytes, assuming 32 \emph{bits} for each PTE. \\
Page tables for larger virtual memories are larger.

\subsection{Page Tables: Where?}
Page tables are kernel data structures, i.e. page tables for all processes are in the kernel's stack.

\subsection{Summary: Roles of the Kernel and the MMU}
Kernel:
\begin{itemize}
  \item Manage MMU registers on address space switches (context switch from thread in one process to thread in a different process)
  \item Create and manage page tables
  \item Manage (allocate/deallocate) physical memory
  \item Handle exceptions raised by the MMU
\end{itemize}
MMU (hardware):
\begin{itemize}
  \item Translate virtual addresses to physical addresses
  \item Check for and raise exceptions when necessary
\end{itemize}

\subsection{TLBs}
Execution of each machine instruction may involve one, two, or more memory operations
\begin{itemize}
  \item one to fetch instruction
  \item one or more for instruction operands
\end{itemize}
Address translation through a page table adds one extra memory operation (for page table entry lookup) for each memory operation performed during instruction execution. \\
This can be slow! \\

Solution: include a \emph{Translation Lookaside Buffer} (TLB) in the MMU,
\begin{itemize}
  \item TLB is a small, fast, dedicated cache for address translation in the MMU
  \item Each TLB entry stores a (page number $\Rightarrow frame number$) mapping
\end{itemize}

\subsection{TLB Use}
What the MMU does to translate a virtual address on page $p$:
\begin{verbatim}
  if there is an entry (p, f) in the TLB then
    return f  /* TLB hit! */
  else
    find p's frame number (f) from the page table
    add (p, f) to the TLB, evicting another entry if full
    return f  /* TLB miss */
\end{verbatim}
If the MMU cannot distinguish TLB entries from different address spaces, then the kernel must \emph{clear} or \emph{invalidate} the TLB on \emph{each} context switch from one process to another! \\

This is a \emph{hardware-managed TLB},
\begin{itemize}
  \item the MMU handles TLB misses, including page table lookup and replacement of TLB entries
  \item MMU must understand the kernel's page table format
\end{itemize}

\subsection{Software-Managed TLBs}
The MIPS has a \emph{software-managed TLB}, which translates a virtual address on page $p$ like this:
\begin{verbatim}
  if there is an entry (p,f) in the TLB then
    return f        /* TLB hit! */
  else
    raise exception /* TLB miss */
\end{verbatim}
In case of a TLB miss, the kernel must
\begin{enumerate}
  \item[1.] determine the frame number of $p$
  \item[2.] add $(p, f)$ to the TLB, evicting another entry if necessary
\end{enumerate}
After the miss is handled, the instruction that caused the exception is re-tried.

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.6]{pictures/mips_tlb.png}
  \caption{The MIPS R3000 TLB}
  \label{fig:mips_tlb}
\end{figure}
The MIPS TLB has room for 64 entries. Each entry is 64 bits (8 bytes) long. \\
See \texttt{kern/arch/mips/include/tlb.h}

\subsection{Large, Sparse Virtual Memories}
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.65]{pictures/real_v_mem.png}
  \caption{A more realistic virtual memory; this is a layout of the virtual address space for \texttt{user/testbin/sort} in OS/161}
  \label{fig:realistic_v_mem}
\end{figure}
Virtual memory may be large,
\begin{itemize}
  \item[MIPS:] $V = 32$, max virtual memory is $2^{32}$ bytes (4 GB)
  \item[x86-64:] $V = 48$, max virtual memory is $2^{48}$ bytes (246 TB)
\end{itemize}
Much of the virtual memory may be unused (see \ref{fig:realistic_v_mem})! \\

Application may use \emph{discontinuous segments} of the virtual memory. \\
One reason is that we have to give room for the stack to grow in the virtual memory!

\subsection{Limitations of Simple Address Translation Approaches}
A kernel that used simple dynamic relocation would have to allocate 2 GB of contiguous physical memory for \texttt{testbin/sort}'s virtual memory, even though \texttt{sort} only uses about 1.2 MB. \\

A kernel that used simple paging would require a page table with $2^{20}$ PTEs (assuming page size is 4 KB) to map \texttt{testbin/sort}'s address space,
\begin{itemize}
  \item this page table is actually larger than the virtual memory that \texttt{sort} needs to use
  \item most of the PTEs are marked as invalid
  \item this page table has to be contiguous in kernel memory
\end{itemize}

\subsection{Segmentation}
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.7]{pictures/seg_addr_space.png}
  \caption{Example of segment address space}
  \label{fig:seg_addr_space}
\end{figure}
Instead of mapping the entire virtual memory to physical, we can provide a separate mapping for each segment of the virtual memory that the application actually uses. \\

Instead of a single offset and limit for the entire address space, the kernel maintains an offset and limit for each segment,
\begin{itemize}
  \item The MMU has multiple offset and limit registers, one pair for each segment
\end{itemize}

With segmentation, a virtual address can be thought of as having two parts: segment ID and offset within segment. \\

With $K$ bits for the segment ID, we can have up to:
\begin{itemize}
  \item $2^{K}$ segments
  \item $2^{V - K}$ bytes per segment
\end{itemize}

The kernel decides where each segment is placed in physical memory.
Fragmentation of physical memory is possible!

\subsection{Translating Segmented Virtual Addresses}
The MMU needs a relocation register and a limit register for each segment,
\begin{itemize}
  \item let $R_{i}$ be the relocation offset for the $i$th segment
  \item let $L_{i}$ be the limit of the $i$th segment
\end{itemize}
To translate virtual address $v$ to a physical address $p$:
\begin{align*}
&\texttt{split } p \texttt{ into segment number }(s)\texttt{ and address within segment }(a) \\
&\texttt{if } a \geq L_{s} \texttt{ then generate exception} \\
&\texttt{else} \\
&\quad p \gets a + R_{i}
\end{align*}
As for dynamic relocation, the kernel maintains a separate set of relocation offsets and limits for each process, and changes the values in the MMU's registers when there is a context switch between processes.

\subsection{Two-Level Paging}
Instead of having a single page table to map an entire virtual memory, we can split the page table into smaller page tables, and add page table directory.
\begin{itemize}
  \item Instead of one larger, contiguous table, we have multiple smaller tables
  \item If all PTEs in a small table are invalid, we can avoid creating that table entirely
\end{itemize}
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.7]{pictures/single_double_paging.png}
  \caption{Single vs. Two Level Paging}
  \label{fig:s_t_paging}
\end{figure}
Each virtual address has three parts:
\begin{enumerate}
  \item[1.] Level one page number: used to index the directory
  \item[2.] Level two page number: used to index a page table
  \item[3.] Offset within the page
\end{enumerate}

\subsection{Address Translation with Two-Level Paging}
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.7]{pictures/two_level_paing_trans.png}
  \caption{Example of two-level address translation}
  \label{fig:two_level_addr_translation}
\end{figure}
The MMU's \emph{page table base register} points to the page table directory for the current process. \\
Each virtual address $v$ has three parts: $(p_{1}, p_{2}, o)$ \\
How the MMU translate a virtual address:
\begin{enumerate}
  \item[1.] Index into the page table directory using $p_{1}$ to get a pointer to a 2nd level page table
  \item[2.] If the directory entry is not valid, raise an exception
  \item[3.] Index into the 2nd level page table using $p_{2}$ to find the PTE for the page being accessed
  \item[4.] If the PTE is not valid, raise an exception
  \item[5.] Otherwise, combine the frame number from the PTE with $o$ to determine the physical address (as for single-level paging)
\end{enumerate}

\subsection{Limits of Two-Level Paging}
A goal of two-level paging was to keep individual page tables small. \\
Suppose we have 40 bit virtual addresses ($V = 40$) and that
\begin{itemize}
  \item the size of a PTE is 4 bytes
  \item page size is 4KB ($2^{12}$ bytes)
  \item we'd like to limit each page table's size to 4KB
\end{itemize}
Problem: for large address spaces, we may need a large page table directory!
\begin{itemize}
  \item There can be up to $2^{28}$ pages in a virtual memory
  \item A single page table can hold $2^{10}$ PTEs
  \item We may need up to $2^{18}$ page tables
  \item Our page table directory will have to have $2^{18}$ entries
  \item If a directory entry is 4 bytes, the directory will occupy 1MB
\end{itemize}
This is the problem we were trying to avoid by introducing a second level!

\subsection{Multi-Level Paging}
We can solve the large directory problem by introducing additional levels of directories. \\
Example: 4-level paging in x86-64 architecture. \\
Properties of Multi-Level Paging:
\begin{itemize}
  \item can map large virtual memories by adding more levels
  \item individual page table/directories can remain small
  \item can avoid allocating page tables and directories that are not needed for programs that use a small amount of virtual memory
  \item TLB misses become \emph{more} expensive as the number of levels goes up, since more directories must be accessed to find the correct PTE
\end{itemize}

\subsection{Virtual Memory in OS/161 on MIPS: \texttt{dumbvm}}
The MIPS uses 32-bit paged virtual and physical addresses. \\
The MIPS has a software-managed TLB,
\begin{itemize}
  \item TLB raises an exception on every TLB miss
  \item kernel is free to record page-to-frame mappings however it wants to
\end{itemize}

TLB exceptions are handled by a kernel function called \texttt{vm\_fault} \\
\texttt{vm\_fault} uses information from an \texttt{addrspace} structure to determine a page-to-frame mapping to load into the TLB,
\begin{itemize}
  \item there is a separate \texttt{addrspace} structure for each process
  \item each \texttt{addrspace} structure describes where its process's pages are stored in physical memory
  \item an \texttt{addrspace} structure does the same job as a page table, but the \texttt{addrspace} structure is simpler because OS/161 places all pages of each segment \emph{contiguously} in physical memory
\end{itemize}

\subsubsection{The \texttt{addrspace} Structure}
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.7]{pictures/addrspace.png}
  \caption{\texttt{addrspace} diagram}
  \label{fig:addrspace}
\end{figure}
\begin{verbatim}
  struct addrspace {
    vaddr_t as_vbase1;      /* base virtual address of code segment */
    paddr_t as_pbase1;      /* base physical address of code segment */
    size_t as_npages1;      /* size (in pages) of code segment */
    vaddr_t as_vbase2;      /* base virtual address of data segment */
    paddr_t as_pbase2;      /* base physical address of data segment */
    size_t as_npages2;      /* size (in pages) of data segment */
    paddr_t as_stackpbase;  /* base physical address of stack */
  };
\end{verbatim}

\subsubsection{Address Translation: OS/161 dumbvm Example}
\textbf{Note}: in OS/161, the stack is 12 pages and the page size is 4 KB = 0x1000. \\
\begin{table}
  \centering
  \begin{tabular}{|r|r|r|}
  \hline
  Variable/Field & Process 1 & Process 2 \\ \hline \hline
  as\_vbase1 & 0x0040 0000 & 0x0040 0000 \\ \hline
  as\_pbase1 & 0x0020 0000 & 0x0050 0000 \\ \hline
  as\_bpages1 & 0x0000 0008 & 0x0000 0002 \\ \hline
  as\_vbase2 & 0x1000 0000 & 0x1000 0000 \\ \hline
  as\_pbase2 & 0x0080 0000 & 0x00A0 0000 \\ \hline
  as\_npages & 0x0000 0010 & 0x0000 0008 \\ \hline
  as\_stackpbase & 0x0010 0000 & 0x00B0 0000 \\ \hline
  \end{tabular}
\end{table}


%%%%%%%%%%%%%%%%
%% SCHEDULING %%
%%%%%%%%%%%%%%%%
\newpage
\section{Scheduling}

\newpage
\section{Devices and Device Management}

\newpage
\section{File Systems}

\newpage
\section{Interprocess Communications and Networking}

\clearpage
\printindex
\end{document}

%%%%%%%%%%%%%%%%%%%%%
%% D O C U M E N T %%
%%%%%%%%%%%%%%%%%%%%%
